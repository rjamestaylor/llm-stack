# LLM Model Benchmarking - Moved to llm-bench

> **Note:** The benchmarking functionality has been moved to a dedicated repository: [llm-bench](https://github.com/rjamestaylor/llm-bench)

## Benchmarking Features Now Available in llm-bench

The llm-bench repository provides comprehensive tools for benchmarking Large Language Models using Ollama:

- **Performance Measurement**: Measure token generation speed, memory usage, CPU utilization
- **Model Comparison**: Compare different models on the same hardware
- **Visualization Tools**: Generate charts and reports for easy analysis
- **Hardware Optimization**: Identify the best models for your specific hardware
- **Metal Acceleration Support**: Optimized for Apple Silicon with Metal acceleration

## Using llm-bench

For all benchmarking needs, please visit the [llm-bench repository](https://github.com/rjamestaylor/llm-bench), which contains:

- Detailed documentation on running benchmarks
- Visualization tools for benchmark results
- Analysis scripts for performance and memory utilization
- Advanced features for GPU metrics and custom benchmarking scenarios

The benchmarking scripts in this directory are maintained for legacy purposes only and will not receive future updates.